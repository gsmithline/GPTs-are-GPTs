{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: igraph in /Users/gabesmithline/miniconda3/envs/gpts-are-gpts/lib/python3.13/site-packages (0.11.8)\n",
      "Requirement already satisfied: scipy in /Users/gabesmithline/miniconda3/envs/gpts-are-gpts/lib/python3.13/site-packages (1.14.1)\n",
      "Requirement already satisfied: pandas in /Users/gabesmithline/miniconda3/envs/gpts-are-gpts/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Users/gabesmithline/miniconda3/envs/gpts-are-gpts/lib/python3.13/site-packages (2.1.3)\n",
      "Requirement already satisfied: matplotlib in /Users/gabesmithline/miniconda3/envs/gpts-are-gpts/lib/python3.13/site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-network in /Users/gabesmithline/miniconda3/envs/gpts-are-gpts/lib/python3.13/site-packages (0.33.1)\n",
      "Requirement already satisfied: scikit-fuzzy in /Users/gabesmithline/miniconda3/envs/gpts-are-gpts/lib/python3.13/site-packages (0.5.0)\n",
      "Collecting matplotlib.colors\n",
      "  Downloading matplotlib_colors-1.0.16-py3-none-any.whl.metadata (4.2 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement matplotlib.collections (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for matplotlib.collections\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install igraph\n",
    "!pip install scipy\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scikit-network\n",
    "!pip install scikit-fuzzy\n",
    "!pip install scikit-fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Packages and functions. Special thanks to Morgan Frank for ThreadedMap, loadBagrowColors, and the functions below!\n",
    "## Accompanying ThreadedMap, loadBagrowColors, and myStats python files must be placed in the python path.\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.collections import LineCollection\n",
    "import pandas as pd\n",
    "#from loadBagrowColors import colors as myColors\n",
    "import igraph as ig\n",
    "#import threadMap\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet, leaves_list\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def echo(X):\n",
    "    return np.array(X)[0]\n",
    "\n",
    "\n",
    "def simpleHist(X, numBins=20):\n",
    "    counts, bins = np.histogram(X, bins=numBins)\n",
    "    plt.plot(bins[:-1], counts, \"k-o\")\n",
    "\n",
    "\n",
    "def clusterMat(M, how=\"average\", **kwargs):\n",
    "    Z = linkage(M, how)\n",
    "    order = leaves_list(Z)\n",
    "    m = M[order, :]\n",
    "    m = m[:, order]\n",
    "    plt.imshow(m, aspect=\"auto\", interpolation=\"nearest\", **kwargs)\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "def RCA(X, binarized=False):\n",
    "    rca = (X / np.sum(X, axis=1, keepdims=True)) / (\n",
    "        np.sum(X, axis=0, keepdims=True) / np.sum(X)\n",
    "    )\n",
    "    if not binarized:\n",
    "        return rca\n",
    "    rca2 = np.zeros(rca.shape)\n",
    "    rca2[(rca > 1)] = 1.0\n",
    "    return rca2\n",
    "\n",
    "\n",
    "def relateFeatures(mat, verbose=True):\n",
    "    # row-wise comparison\n",
    "    # defaults to Sorenson Similarity\n",
    "    numRows = mat.shape[0]\n",
    "    out = np.zeros((numRows, numRows))\n",
    "    S = np.sum(mat, axis=1)\n",
    "    progress = 0.1\n",
    "    for i in range(numRows):\n",
    "        out[i, :] = 2 * np.dot(mat, mat[i, :]) / (S + S[i])\n",
    "        if verbose and i / numRows >= progress:\n",
    "            print(\"%0.2f\" % progress)\n",
    "            while progress <= i / numRows:\n",
    "                progress += 0.1\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_rca(temp):\n",
    "    # should be:\n",
    "    #  rows: jobs (or cities)\n",
    "    #  columns: skills\n",
    "    return (temp / np.sum(temp, axis=1, keepdims=True)) / (\n",
    "        np.sum(temp, axis=0, keepdims=True) / temp.sum()\n",
    "    )\n",
    "\n",
    "\n",
    "def findIndex(x, X):\n",
    "    for i in range(len(X)):\n",
    "        if X[i] == x:\n",
    "            return i\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab20_colorNames = [\n",
    "    \"dark blue\",\n",
    "    \"light blue\",\n",
    "    \"orange\",\n",
    "    \"light orange\",\n",
    "    \"dark green\",\n",
    "    \"light green\",\n",
    "    \"red\",\n",
    "    \"light red\",\n",
    "    \"purple\",\n",
    "    \"light purple\",\n",
    "    \"brown\",\n",
    "    \"light brown\",\n",
    "    \"pink\",\n",
    "    \"light pink\",\n",
    "    \"grey\",\n",
    "    \"light grey\",\n",
    "    \"pale green\",\n",
    "    \"light pale green\",\n",
    "    \"cyan\",\n",
    "    \"light cyan\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Users/gabesmithline/Desktop/GPTs-are-GPTs/data/task_ratings_file_7-12.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m curdir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsers/gabesmithline/Desktop/GPTs-are-GPTs/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m## data read-in\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m jobTasksIn \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mdata/task_ratings_file_7-12.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m taskDWAS \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mdata/DWA_Tasks_Labels.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpts-are-gpts/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpts-are-gpts/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/gpts-are-gpts/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpts-are-gpts/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/gpts-are-gpts/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Users/gabesmithline/Desktop/GPTs-are-GPTs/data/task_ratings_file_7-12.csv'"
     ]
    }
   ],
   "source": [
    "## file read-ins\n",
    "\n",
    "## set your working directory here and drop the data folder in it!\n",
    "curdir = \"Users/gabesmithline/Desktop/GPTs-are-GPTs/\"\n",
    "\n",
    "## data read-in\n",
    "jobTasksIn = pd.read_csv(f\"{curdir}data/task_ratings_file_7-12.csv\")\n",
    "taskDWAS = pd.read_csv(f\"{curdir}data/DWA_Tasks_Labels.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskDWAS = taskDWAS[\n",
    "    [\"O*NET-SOC Code\", \"Task ID\", \"DWA ID\", \"DWA Title\"]\n",
    "].drop_duplicates()\n",
    "jobTasksDWAs = pd.merge(\n",
    "    jobTasksIn, taskDWAS, how=\"inner\", on=[\"Task ID\", \"O*NET-SOC Code\"]\n",
    ")\n",
    "jobDWAs = (\n",
    "    jobTasksDWAs[\n",
    "        [item for item in list(jobTasksDWAs) if item not in [\"Task\", \"Task ID\"]]\n",
    "    ]\n",
    "    .groupby([\"O*NET-SOC Code\", \"DWA Title\", \"DWA ID\", \"Title\"])\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "jobTasks = jobDWAs[\n",
    "    [\n",
    "        \"O*NET-SOC Code\",\n",
    "        \"Title\",\n",
    "        \"DWA ID\",\n",
    "        \"DWA Title\",\n",
    "        \"mean_rating_human_alpha\",\n",
    "        \"gpt4_rubric1_alpha\",\n",
    "    ]\n",
    "].copy()\n",
    "temp = jobTasks.copy()\n",
    "\n",
    "\n",
    "def getTemp():\n",
    "    temp = jobTasks.copy()\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting parameters for the network plot. this is important!!\n",
    "jobTitles = temp[\"Title\"].unique()\n",
    "DWAs = temp[\"DWA Title\"].unique()\n",
    "rating_desired = (\n",
    "    \"mean_rating_human_alpha\"  # this is where we set the rating we're trying to plot!\n",
    ")\n",
    "\n",
    "\n",
    "def getJobTitle(code):\n",
    "    x = jobTasks[jobTasks[\"O*NET-SOC Code\"] == code]\n",
    "    if x[\"Title\"].count() > 0:\n",
    "        return x.iloc[0][\"Title\"]\n",
    "    return \"Missing job code!\"\n",
    "\n",
    "\n",
    "numJobs = len(jobTitles)\n",
    "numDWA = len(DWAs)\n",
    "print(\"#Jobs: %d, #DWA: %d\" % (numJobs, numDWA))\n",
    "jobDwaMat = np.zeros((numJobs, numDWA))\n",
    "SML = np.zeros(numDWA)\n",
    "\n",
    "\n",
    "def findIndex(x, X):\n",
    "    for i in range(len(X)):\n",
    "        if X[i] == x:\n",
    "            return i\n",
    "    return i\n",
    "\n",
    "\n",
    "count = -1\n",
    "progress = 0.1\n",
    "total = float(temp[\"Title\"].count())\n",
    "for _, row in temp.iterrows():\n",
    "    count += 1\n",
    "    job, dwa = row[\"Title\"], row[\"DWA Title\"]\n",
    "    jobIndex = findIndex(job, jobTitles)\n",
    "    dwaIndex = findIndex(dwa, DWAs)\n",
    "    jobDwaMat[jobIndex, dwaIndex] = 1\n",
    "    SML[dwaIndex] = row[rating_desired]\n",
    "    if count / total >= progress:\n",
    "        print(\"%0.2f\" % progress)\n",
    "        while progress <= count / total:\n",
    "            progress += 0.1\n",
    "\n",
    "jobDwaRca = RCA(jobDwaMat)\n",
    "jobDwaRca2 = RCA(jobDwaMat, True)\n",
    "\n",
    "dwaDwa = np.nan_to_num(relateFeatures(jobDwaRca2.T, verbose=False))\n",
    "jobJob = np.nan_to_num(relateFeatures(jobDwaRca2, verbose=False))\n",
    "\n",
    "plt.figure()\n",
    "clusterMat(dwaDwa)\n",
    "plt.figure()\n",
    "clusterMat(jobJob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## network build code\n",
    "\n",
    "\n",
    "def buildGraph(mat, nodeLabels):\n",
    "    G = ig.Graph(directed=False)\n",
    "    for i in range(mat.shape[0]):\n",
    "        G.add_vertex(i, title=nodeLabels[i])\n",
    "    edgeData = []\n",
    "    for i in range(mat.shape[0]):\n",
    "        for j in range(i + 1, mat.shape[0]):\n",
    "            if mat[i, j] > 0:\n",
    "                edgeData.append([i, j, mat[i, j]])\n",
    "    G.add_edges([(e[0], e[1]) for e in edgeData])\n",
    "    G.es[\"weight\"] = [e[2] for e in edgeData]\n",
    "    G.vs[\"louvain community\"] = np.array(\n",
    "        G.community_multilevel(weights=\"weight\").membership\n",
    "    )\n",
    "    layout = G.layout_fruchterman_reingold(weights=\"weight\", niter=1000)\n",
    "    layout = np.array(layout.coords)\n",
    "    G.vs[\"x\"] = layout[:, 0]\n",
    "    G.vs[\"y\"] = layout[:, 1]\n",
    "    return G\n",
    "\n",
    "\n",
    "def plotNetwork(\n",
    "    G,\n",
    "    layout=None,\n",
    "    nodeColors=None,\n",
    "    linewidth=1,\n",
    "    nodeSize=10,\n",
    "    lineColor=[0, 0, 0, 0.3],\n",
    "    nodeAlpha=1,\n",
    "    cmap=plt.cm.tab10,\n",
    "    fileName=None,\n",
    "):\n",
    "    numNodes = len(G.vs)\n",
    "    if nodeColors is None:\n",
    "        nodeColors = [[0, 0, 0] for i in range(numNodes)]\n",
    "    if layout is None:\n",
    "        layout = np.array(G.layout_fruchterman_reingold().coords)\n",
    "    lines = []\n",
    "    for e in G.es:\n",
    "        p1, p2 = layout[e.source, :], layout[e.target, :]\n",
    "        lines.append([p1, p2])\n",
    "    lines = np.array(lines)\n",
    "    lc = LineCollection(lines, linewidths=linewidth, colors=lineColor)\n",
    "    plt.gca().add_collection(lc)\n",
    "    plt.scatter(\n",
    "        layout[:, 0],\n",
    "        layout[:, 1],\n",
    "        s=nodeSize,\n",
    "        c=nodeColors,\n",
    "        zorder=3,\n",
    "        cmap=cmap,\n",
    "        alpha=nodeAlpha,\n",
    "    )\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(\"off\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    if not fileName is None:\n",
    "        plt.savefig(fileName, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def wrapNetPlot(G, filename=None, C=None):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    degrees = np.array(G.degree())\n",
    "    d, D = np.min(degrees), np.max(degrees)\n",
    "    layout = np.vstack((G.vs[\"x\"], G.vs[\"y\"])).T\n",
    "    if C is None:\n",
    "        C = np.array(G.vs[\"louvain community\"])\n",
    "        cc = plt.cm.tab20.colors\n",
    "        C = [cc[c % len(cc)] for c in C]\n",
    "    plotNetwork(\n",
    "        G,\n",
    "        layout,\n",
    "        nodeColors=C,\n",
    "        nodeSize=25 * (degrees - d) / (D - d) + 10,\n",
    "        lineColor=[0.3, 0.3, 0.3, 0.1],\n",
    "        linewidth=1,\n",
    "        nodeAlpha=1,\n",
    "        fileName=filename,\n",
    "    )\n",
    "    print(\n",
    "        \"network modularity: %0.3f, # node communities: %d\"\n",
    "        % (\n",
    "            G.modularity(G.vs[\"louvain community\"], weights=\"weight\"),\n",
    "            np.max(G.vs[\"louvain community\"]) + 1,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobNetwork = buildGraph(jobJob, jobTitles)\n",
    "\n",
    "## plots the network of jobs (not colored by exposure)\n",
    "wrapNetPlot(jobNetwork, f\"{curdir}/gpt_jobNetwork.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## outputs the clusters\n",
    "Fout = open(f\"{curdir}/jobNetworkCommunities.csv\", \"w\")\n",
    "Fout.write(\"Community\\tColor\\tJob Title\\n\")\n",
    "for i in range(np.max(jobNetwork.vs[\"louvain community\"]) + 1):\n",
    "    print((i, tab20_colorNames[i]))\n",
    "    V = [v[\"title\"] for v in jobNetwork.vs if v[\"louvain community\"] == i]\n",
    "    print(V)\n",
    "    print(\"--------\")\n",
    "    for v in V:\n",
    "        Fout.write(\"%d\\t%s\\t%s\\n\" % (i, tab20_colorNames[i], v))\n",
    "Fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobType = []\n",
    "for v in jobNetwork.vs:\n",
    "    jobType.append({\"Title\": v[\"title\"], \"Type\": v[\"louvain community\"]})\n",
    "jobType = pd.DataFrame(jobType)\n",
    "\n",
    "temp = pd.merge(getTemp(), jobType)\n",
    "T = (\n",
    "    temp.groupby(\"Type\")\n",
    "    .agg(\n",
    "        {\n",
    "            f\"{rating_desired}\": [\n",
    "                np.mean,\n",
    "                np.median,\n",
    "                np.std,\n",
    "                lambda x: np.std(x) / np.sqrt(len(x)),\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "T.columns = T.columns.map(\"\".join)\n",
    "T = T.sort_values(by=f\"{rating_desired}mean\")\n",
    "\n",
    "# map for cluster names\n",
    "occtypes = {\n",
    "    0: \"Managers\",\n",
    "    1: \"Clerks and Services\",\n",
    "    2: \"Technologists\",\n",
    "    3: \"Architects and Engineers\",\n",
    "    4: \"Scientists and Researchers\",\n",
    "    5: \"Medical Workers\",\n",
    "    6: \"Legal Services\",\n",
    "    7: \"Teachers\",\n",
    "    8: \"Arts, Media, and Entertainment\",\n",
    "    9: \"Operators\",\n",
    "    10: \"Machinists\",\n",
    "}\n",
    "\n",
    "# save clusters\n",
    "temp[\"jobGroup\"] = temp[\"Type\"].map(occtypes)\n",
    "T[\"jobArchetypeName\"] = T.Type.map(occtypes)\n",
    "temp.to_csv(f\"{curdir}data/jobNetworkMembershipWithTypes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cluster plot with means\n",
    "plt.figure()\n",
    "for i in range(T[\"jobArchetypeName\"].count()):\n",
    "    plt.errorbar(\n",
    "        T[f\"{rating_desired}mean\"].iloc[i],\n",
    "        i,\n",
    "        xerr=1.96 * T[f\"{rating_desired}<lambda_0>\"].iloc[0],\n",
    "        fmt=\"o\",\n",
    "        markersize=4,\n",
    "        color=plt.cm.tab20.colors[T[\"Type\"].iloc[i]],\n",
    "    )\n",
    "\n",
    "# x =\n",
    "plt.yticks(np.arange(T[\"Type\"].count()), T[\"jobArchetypeName\"], fontsize=15)\n",
    "plt.ylabel(\"Job Grouping\", fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.xlabel(\"Avg. LLM Exposure (E1)\\n by Job Group\", fontsize=15)\n",
    "plt.savefig(f\"{curdir}/data/vecfigs/gptByJobType.pdf\", bbox_inches=\"tight\")\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobNetwork.vs.attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now to look at detailed work activities (DWAs)\n",
    "## build network\n",
    "dwaNetwork = buildGraph(dwaDwa, DWAs)\n",
    "wrapNetPlot(dwaNetwork, f\"{curdir}/dwaNetwork.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwaType = []\n",
    "for v in dwaNetwork.vs:\n",
    "    dwaType.append({\"DWA Title\": v[\"title\"], \"DWA Type\": v[\"louvain community\"]})\n",
    "dwaType = pd.DataFrame(dwaType)\n",
    "temp = pd.merge(temp, dwaType)\n",
    "T = temp.groupby(\"Type\").agg({f\"{rating_desired}\": np.mean}).reset_index()\n",
    "TT = temp.groupby(\"Title\").agg({f\"{rating_desired}\": np.mean}).reset_index()\n",
    "for v in jobNetwork.vs:\n",
    "    x = T[T[\"Type\"] == v[\"louvain community\"]]\n",
    "    v[f\"type {rating_desired}\"] = x.iloc[0][f\"{rating_desired}\"]\n",
    "    x = TT[TT[\"Title\"] == v[\"title\"]]\n",
    "    v[f\"{rating_desired}\"] = x.iloc[0][f\"{rating_desired}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## network plot colored by exposure\n",
    "plt.figure(figsize=(10, 8))\n",
    "layout = np.vstack((jobNetwork.vs[\"x\"], jobNetwork.vs[\"y\"])).T\n",
    "plotNetwork(\n",
    "    jobNetwork,\n",
    "    layout,\n",
    "    nodeColors=jobNetwork.vs[f\"type {rating_desired}\"],\n",
    "    nodeSize=10,\n",
    "    lineColor=[0.3, 0.3, 0.3, 0.1],\n",
    "    linewidth=1,\n",
    "    cmap=plt.cm.viridis,\n",
    ")\n",
    "C = plt.colorbar()\n",
    "C.ax.tick_params(labelsize=15)\n",
    "# C.set_label(f\"Job Type {rating_desired}\",fontsize=15)\n",
    "C.set_label(f\"Human Ratings for LLM-Exposure\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{curdir}/gpt_jobnetwork.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write clusters to file\n",
    "Fout = open(f\"{curdir}/dwaNetworkCommunities.csv\", \"w\")\n",
    "Fout.write(\"Community\\tColor\\tDWA Title\\n\")\n",
    "for i in range(np.max(dwaNetwork.vs[\"louvain community\"]) + 1):\n",
    "    print((i, tab20_colorNames[i]))\n",
    "    V = [v[\"title\"] for v in dwaNetwork.vs if v[\"louvain community\"] == i]\n",
    "    print(V)\n",
    "    print(\"--------\")\n",
    "    for v in V:\n",
    "        Fout.write(\"%d\\t%s\\t%s\\n\" % (i, tab20_colorNames[i], v))\n",
    "Fout.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
